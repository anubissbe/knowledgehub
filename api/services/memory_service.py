"""Memory management service"""

from sqlalchemy.orm import Session
from sqlalchemy import desc, func
from typing import List, Optional, Dict, Any
from uuid import UUID, uuid4
from datetime import datetime, timedelta
import hashlib
import json

from ..models.memory import MemoryItem
from ..schemas.memory import MemoryCreate


class MemoryService:
    """Service for managing system memory and conversation history"""
    
    def __init__(self):
        """Initialize without dependencies - they'll be injected per request"""
        pass
    
    async def create_memory(self, db: Session, memory_data: MemoryCreate) -> MemoryItem:
        """Create a new memory entry"""
        # Generate content hash
        content_hash = self._generate_hash(memory_data.content)
        
        # Check for duplicate
        existing = db.query(MemoryItem).filter(
            MemoryItem.content_hash == content_hash
        ).first()
        
        if existing:
            # Update access count and timestamp
            existing.access_count += 1
            existing.accessed_at = datetime.utcnow()
            db.commit()
            return existing
        
        # Create new memory
        memory = MemoryItem(
            id=uuid4(),
            content=memory_data.content,
            content_hash=content_hash,
            tags=memory_data.tags or [],
            meta_data=memory_data.metadata or {},
            embedding_id=None,  # Would be generated by embedding service
            created_at=datetime.utcnow(),
            accessed_at=datetime.utcnow(),
            access_count=1
        )
        
        db.add(memory)
        db.commit()
        db.refresh(memory)
        
        # Store in vector store if available
        from .vector_store import vector_store
        if hasattr(vector_store, 'client') and vector_store.client:
            # In production, generate real embeddings
            mock_embedding = [0.1] * 384  # Match the system's embedding dimension
            
            await vector_store.insert_chunk(
                chunk_data={
                    "memory_id": str(memory.id),
                    "content": memory.content,
                    "tags": memory.tags if memory.tags else [],
                    "metadata": json.dumps(memory.meta_data) if memory.meta_data else "{}",
                    "created_at": memory.created_at.isoformat()
                },
                vector=mock_embedding
            )
        
        return memory
    
    def get_memory(self, db: Session, memory_id: UUID) -> Optional[MemoryItem]:
        """Get a memory by ID"""
        memory = db.query(MemoryItem).filter(MemoryItem.id == memory_id).first()
        
        if memory:
            # Update access info
            memory.access_count += 1
            memory.accessed_at = datetime.utcnow()
            db.commit()
        
        return memory
    
    def get_memories(
        self,
        db: Session,
        memory_type: Optional[str] = None,
        source: Optional[str] = None,
        skip: int = 0,
        limit: int = 100
    ) -> List[MemoryItem]:
        """Get memories with optional filtering"""
        query = db.query(MemoryItem)
        
        # For now, we'll ignore memory_type and source filters since they're stored in metadata/tags
        # In the future, we could filter by JSON metadata or tags array
        
        return query.order_by(desc(MemoryItem.created_at)).offset(skip).limit(limit).all()
    
    async def search_memories(
        self,
        db: Session,
        query_text: str,
        memory_type: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """Search memories using vector similarity or keyword search"""
        from .vector_store import vector_store
        
        # Try vector search first if available
        if hasattr(vector_store, 'client') and vector_store.client:
            # In production, generate query embedding
            query_vector = [0.1] * 768
            
            filters = {}
            if memory_type:
                filters["tags"] = memory_type
            
            results = await vector_store.search(
                query_vector=query_vector,
                limit=limit,
                filters=filters
            )
            
            # Enhance with database data
            enhanced_results = []
            for result in results:
                memory = db.query(MemoryItem).filter(
                    MemoryItem.id == result.get("memory_id")
                ).first()
                
                if memory:
                    enhanced_results.append({
                        "memory": memory,
                        "score": result.get("score", 0)
                    })
            
            return enhanced_results
        
        # Fallback to keyword search
        memories = db.query(MemoryItem).filter(
            func.lower(MemoryItem.content).contains(query_text.lower())
        )
        
        # For now, skip memory_type filtering in fallback search
        
        memories = memories.limit(limit).all()
        
        return [{"memory": m, "score": 1.0} for m in memories]
    
    def get_recent_memories(
        self,
        db: Session,
        hours: int = 24,
        memory_type: Optional[str] = None
    ) -> List[MemoryItem]:
        """Get memories from the last N hours"""
        cutoff = datetime.utcnow() - timedelta(hours=hours)
        
        query = db.query(MemoryItem).filter(
            MemoryItem.created_at >= cutoff
        )
        
        # For now, skip memory_type filtering
        
        return query.order_by(desc(MemoryItem.created_at)).all()
    
    def get_memory_stats(self, db: Session) -> Dict[str, Any]:
        """Get memory statistics"""
        total = db.query(MemoryItem).count()
        
        # For now, skip counts by type and source since they're stored in metadata/tags
        
        # Get most accessed
        most_accessed = db.query(MemoryItem).order_by(
            desc(MemoryItem.access_count)
        ).limit(10).all()
        
        return {
            "total": total,
            "by_type": {},
            "by_source": {},
            "most_accessed": [
                {
                    "id": str(m.id),
                    "content": m.content[:100] + "..." if len(m.content) > 100 else m.content,
                    "access_count": m.access_count
                }
                for m in most_accessed
            ]
        }
    
    def _generate_hash(self, content: str) -> str:
        """Generate SHA256 hash of content"""
        return hashlib.sha256(content.encode()).hexdigest()
    
    async def cleanup_old_memories(
        self,
        db: Session,
        days: int = 30,
        min_access_count: int = 2
    ) -> int:
        """Clean up old, rarely accessed memories"""
        cutoff = datetime.utcnow() - timedelta(days=days)
        
        # Find memories to delete
        to_delete = db.query(MemoryItem).filter(
            MemoryItem.created_at < cutoff,
            MemoryItem.access_count < min_access_count
        ).all()
        
        count = len(to_delete)
        
        # Delete from vector store if available
        from .vector_store import vector_store
        if hasattr(vector_store, 'client') and vector_store.client:
            for memory in to_delete:
                # In production, would delete from vector store
                pass
        
        # Delete from database
        for memory in to_delete:
            db.delete(memory)
        
        db.commit()
        
        return count